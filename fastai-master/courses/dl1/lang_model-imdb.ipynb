{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.core import *\n",
    "from fastai.model import fit\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs,bptt = 64,70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz  imdbEr.txt  imdb.vocab  \u001b[0m\u001b[01;34mmodels\u001b[0m/  README  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtmp\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/aclImdb/'\n",
    "\n",
    "TRN_PATH = 'train/all/'\n",
    "VAL_PATH = 'test/all/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0.txt\n",
      "0_3.txt\n",
      "0_9.txt\n",
      "10000_0.txt\n",
      "10000_4.txt\n",
      "10000_8.txt\n",
      "1000_0.txt\n",
      "10001_0.txt\n",
      "10001_10.txt\n",
      "10001_4.txt\n",
      "ls: write error\n"
     ]
    }
   ],
   "source": [
    "%ls {TRN} | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have to say when a name like Zombiegeddon and an atom bomb on the front cover I was expecting a flat out chop-socky fung-ku, but what I got instead was a comedy. So, it wasn't quite was I was expecting, but I really liked it anyway! The best scene ever was the main cop dude pulling those kids over and pulling a Bad Lieutenant on them!! I was laughing my ass off. I mean, the cops were just so bad! And when I say bad, I mean The Shield Vic Macky bad. But unlike that show I was laughing when they shot people and smoked dope.<br /><br />Felissa Rose...man, oh man. What can you say about that hottie. She was great and put those other actresses to shame. She should work more often!!!!! I also really liked the fight scene outside of the building. That was done really well. Lots of fighting and people getting their heads banged up. FUN! Last, but not least Joe Estevez and William Smith were great as the...well, I wasn't sure what they were, but they seemed to be having fun and throwing out lines. I mean, some of it didn't make sense with the rest of the flick, but who cares when you're laughing so hard! All in all the film wasn't the greatest thing since sliced bread, but I wasn't expecting that. It was a Troma flick so I figured it would totally suck. It's nice when something surprises you but not totally sucking.<br /><br />Rent it if you want to get stoned on a Friday night and laugh with your buddies. Don't rent it if you are an uptight weenie or want a zombie movie with lots of flesh eating.<br /><br />P.S. Uwe Boil was a nice touch."
     ]
    }
   ],
   "source": [
    "!cat {TRN}1000_0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17486581\r\n"
     ]
    }
   ],
   "source": [
    "!find {TRN} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5686719\r\n"
     ]
    }
   ],
   "source": [
    "!find {VAL} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=spacy_tok)\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4602, 34945, 1, 20621966, 34945)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is', 'it', 'in']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i',\n",
       "  'just',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'get',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'big',\n",
       "  'premises',\n",
       "  'of',\n",
       "  'this'],\n",
       " (Variable containing:\n",
       "      12    687     13  ...    1923     19     17\n",
       "      51    615     25  ...      10     63     51\n",
       "      53      3      3  ...      42    428    833\n",
       "          ...            ⋱           ...         \n",
       "      51     64      3  ...     111    544      6\n",
       "       6      2   2075  ...      90     43    552\n",
       "    3343   4351      5  ...      35      2    249\n",
       "  [torch.cuda.LongTensor of size 61x64 (GPU 0)], Variable containing:\n",
       "      51\n",
       "     615\n",
       "      25\n",
       "    ⋮   \n",
       "      93\n",
       "     406\n",
       "      43\n",
       "  [torch.cuda.LongTensor of size 3904 (GPU 0)]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:12], next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_sz = 200\n",
    "nh = 500\n",
    "nl = 3\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4146d1266fba4e6983bd939385726533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.      4.6754  4.5553]                                     \n",
      "[ 1.      4.5344  4.4255]                                     \n",
      "[ 2.      4.4838  4.389 ]                                     \n",
      "[ 3.      4.5597  4.4271]                                     \n",
      "[ 4.      4.4565  4.3472]                                     \n",
      "[ 5.      4.4095  4.3167]                                     \n",
      "[ 6.      4.5065  4.3852]                                     \n",
      "[ 7.      4.4273  4.3122]                                     \n",
      "[ 8.      4.3651  4.2831]                                     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95863770c414e5fb1a23730865cb9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.      4.5019  4.3872]                                     \n",
      "[ 1.      4.4707  4.3654]                                     \n",
      "[ 2.      4.4606  4.3432]                                     \n",
      "[ 3.      4.4183  4.3185]                                     \n",
      "[ 4.      4.3858  4.2928]                                     \n",
      "[ 5.      4.368   4.2717]                                     \n",
      "[ 6.      4.3286  4.2485]                                     \n",
      "[ 7.      4.3101  4.2333]                                     \n",
      "[ 8.      4.2913  4.2256]                                     \n",
      "[ 9.      4.2581  4.2244]                                     \n",
      "[ 10.       4.4615   4.3373]                                  \n",
      "[ 11.       4.4281   4.3265]                                  \n",
      "[ 12.       4.4209   4.3076]                                  \n",
      "[ 13.       4.3941   4.2883]                                  \n",
      "[ 14.       4.3655   4.2645]                                  \n",
      "[ 15.       4.3298   4.242 ]                                  \n",
      "[ 16.       4.3018   4.2229]                                  \n",
      "[ 17.       4.2902   4.2097]                                  \n",
      "[ 18.       4.2603   4.2021]                                  \n",
      "[ 19.       4.2465   4.2011]                                  \n",
      "[ 20.       4.4299   4.3136]                                  \n",
      "[ 21.       4.4141   4.308 ]                                  \n",
      "[ 22.       4.4116   4.2911]                                  \n",
      "[ 23.       4.3732   4.2714]                                  \n",
      "[ 24.       4.3494   4.2503]                                  \n",
      "[ 25.       4.2977   4.2267]                                  \n",
      "[ 26.       4.2706   4.2093]                                  \n",
      "[ 27.       4.2783   4.1968]                                  \n",
      "[ 28.       4.2793   4.1893]                                  \n",
      "[ 29.       4.2252   4.1872]                                  \n",
      "[ 30.       4.4068   4.3006]                                  \n",
      "[ 31.       4.3984   4.2935]                                  \n",
      "[ 32.       4.3713   4.2759]                                  \n",
      "[ 33.       4.364    4.2602]                                  \n",
      "[ 34.       4.3187   4.2406]                                  \n",
      "[ 35.       4.3037   4.2196]                                  \n",
      "[ 36.       4.2787   4.2003]                                  \n",
      "[ 37.       4.2539   4.1871]                                  \n",
      "[ 38.       4.2175   4.1801]                                  \n",
      "[ 39.       4.2048   4.1788]                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=10, cycle_save_name='adam3_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b91e83ce196468e97ed5d74f7f38851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.      4.2122  4.1803]                                     \n",
      "[ 1.      4.4048  4.2924]                                     \n",
      "[ 2.      4.4049  4.292 ]                                     \n",
      "[ 3.      4.3769  4.2839]                                     \n",
      "[ 4.      4.3734  4.2757]                                     \n",
      "[ 5.      4.3558  4.2684]                                     \n",
      "[ 6.      4.3471  4.2587]                                     \n",
      "[ 7.      4.3372  4.2475]                                     \n",
      "[ 8.      4.3426  4.2398]                                     \n",
      "[ 9.      4.3155  4.2253]                                     \n",
      "[ 10.       4.2975   4.2165]                                  \n",
      "[ 11.       4.2747   4.2057]                                  \n",
      "[ 12.       4.2725   4.1949]                                  \n",
      "[ 13.       4.2533   4.1861]                                  \n",
      "[ 14.       4.2281   4.1788]                                  \n",
      "[ 15.       4.226    4.1729]                                  \n",
      "[ 16.       4.222    4.1689]                                  \n",
      "[ 17.       4.203    4.1655]                                  \n",
      "[ 18.       4.1878   4.1646]                                  \n",
      "[ 19.       4.1799   4.1646]                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=20, cycle_save_name='adam3_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.3926824434624"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(4.165)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\". So , it was n't quite was I was expecting , but I really liked it anyway ! The best\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=learner.model\n",
    "s=\"\"\". So, it wasn't quite was I was expecting, but I really liked it anyway! The best\"\"\"\n",
    "s = [spacy_tok(s)]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "res,*_ = m(t)\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['performance',\n",
       " 'of',\n",
       " 'friend',\n",
       " 'actor',\n",
       " 'thing',\n",
       " 'scene',\n",
       " 'character',\n",
       " 'part',\n",
       " 'line',\n",
       " 'movie']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance was the one in the movie where he was a little too old for the part . i think "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMDB_LABEL = data.Field(sequential=False)\n",
    "splits = torchtext.datasets.IMDB.splits(TEXT, IMDB_LABEL, 'data/')\n",
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout=0.4, dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5\n",
    "#            dropout=0.3, dropouti=0.4, wdrop=0.3, dropoute=0.05, dropouth=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.clip=25.\n",
    "m3.load_encoder(f'adam3_20_enc')\n",
    "lrs=np.array([1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde7ebf1a9ee4144a9f87ffec627bfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.      0.43    0.2399  0.9075]                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87ee8ce7a9548e08b03385ca8cda635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.      0.3     0.1924  0.9272]                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m3.freeze_to(-1)\n",
    "m3.fit(lrs/2, 1, metrics=[accuracy])\n",
    "m3.unfreeze()\n",
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65f58990d7341c7a684e28e80cc6add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.      0.275   0.1847  0.9306]                            \n",
      "[ 1.      0.2528  0.1781  0.9336]                            \n",
      "[ 2.      0.2448  0.1729  0.9365]                            \n",
      "[ 3.      0.2052  0.1721  0.9378]                            \n",
      "[ 4.      0.2239  0.1619  0.9413]                            \n",
      "[ 5.      0.1956  0.1628  0.9417]                            \n",
      "[ 6.      0.2093  0.158   0.9421]                            \n",
      "[ 7.      0.1733  0.1591  0.9432]                            \n",
      "[ 8.      0.1916  0.1552  0.9443]                            \n",
      "[ 9.      0.1652  0.157   0.9451]                            \n",
      "[ 10.       0.1749   0.1609   0.9427]                        \n",
      "[ 11.       0.147    0.1579   0.9441]                        \n",
      "[ 12.       0.1554   0.1626   0.942 ]                        \n",
      "[ 13.       0.1302   0.1603   0.9437]                        \n",
      "[ 14.       0.1346   0.1802   0.9384]                        \n",
      "[ 15.       0.1425   0.1711   0.941 ]                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "m3.fit(lrs, 8, metrics=[accuracy], cycle_len=2, cycle_save_name='imdb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m3.load_cycle('imdb2', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94511217948717952"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(*m3.predict_with_targs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_snapshot(learner, name, cycle):\n",
    "    learner.load_cycle(name, cycle)\n",
    "    return learner.predict_with_targs()\n",
    "\n",
    "cyc_preds = [pred_snapshot(m3, 'imdb2', i) for i in range(4,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = [p[0] for p in cyc_preds[:]]\n",
    "y = cyc_preds[0][1]\n",
    "print(accuracy(np.mean(preds,0),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Aux task, not just pretrain\n",
    "- Attention, not just average pool\n",
    "- Pretrain language model on wikitext-103\n",
    "- Bidi RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import ctypes\n",
    "\n",
    "CUDA_SUCCESS = 0\n",
    "CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT = 16\n",
    "CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR = 39\n",
    "CU_DEVICE_ATTRIBUTE_CLOCK_RATE = 13\n",
    "CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE = 36\n",
    "\n",
    "libnames = ('libcuda.so', 'libcuda.dylib', 'cuda.dll')\n",
    "for libname in libnames:\n",
    "    try:\n",
    "        cuda = ctypes.CDLL(libname)\n",
    "    except OSError:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "else:\n",
    "    raise OSError(\"could not load any of: \" + ' '.join(libnames))\n",
    "\n",
    "nGpus = ctypes.c_int()\n",
    "name = b' ' * 100\n",
    "freeMem = ctypes.c_size_t()\n",
    "totalMem = ctypes.c_size_t()\n",
    "\n",
    "result = ctypes.c_int()\n",
    "device = ctypes.c_int()\n",
    "context = ctypes.c_void_p()\n",
    "error_str = ctypes.c_char_p()\n",
    "\n",
    "result = cuda.cuInit(0)\n",
    "if result != CUDA_SUCCESS:\n",
    "    cuda.cuGetErrorString(result, ctypes.byref(error_str))\n",
    "    print(\"cuInit failed with error code %d: %s\" % (result, error_str.value.decode()))\n",
    "result = cuda.cuDeviceGetCount(ctypes.byref(nGpus))\n",
    "if result != CUDA_SUCCESS:\n",
    "    cuda.cuGetErrorString(result, ctypes.byref(error_str))\n",
    "    print(\"cuDeviceGetCount failed with error code %d: %s\" % (result, error_str.value.decode()))\n",
    "print(\"Found %d device(s).\" % nGpus.value)\n",
    "\n",
    "i=0\n",
    "result = cuda.cuDeviceGet(ctypes.byref(device), i)\n",
    "if result != CUDA_SUCCESS:\n",
    "    cuda.cuGetErrorString(result, ctypes.byref(error_str))\n",
    "    print(\"cuDeviceGet failed with error code %d: %s\" % (result, error_str.value.decode()))\n",
    "print(\"Device: %d\" % i)\n",
    "if cuda.cuDeviceGetName(ctypes.c_char_p(name), len(name), device) == CUDA_SUCCESS:\n",
    "    print(\"  Name: %s\" % (name.split(b'\\0', 1)[0].decode()))\n",
    "result = cuda.cuCtxCreate(ctypes.byref(context), 0, device)\n",
    "if result != CUDA_SUCCESS:\n",
    "    cuda.cuGetErrorString(result, ctypes.byref(error_str))\n",
    "    print(\"cuCtxCreate failed with error code %d: %s\" % (result, error_str.value.decode()))\n",
    "else:\n",
    "    result = cuda.cuMemGetInfo(ctypes.byref(freeMem), ctypes.byref(totalMem))\n",
    "    if result == CUDA_SUCCESS:\n",
    "        print(\"  Total Memory: %ld MiB\" % (totalMem.value / 1024**2))\n",
    "        print(\"  Free Memory: %ld MiB\" % (freeMem.value / 1024**2))\n",
    "    else:\n",
    "        cuda.cuGetErrorString(result, ctypes.byref(error_str))\n",
    "        print(\"cuMemGetInfo failed with error code %d: %s\" % (result, error_str.value.decode()))\n",
    "    cuda.cuCtxDetach(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10386.25, 11172.375)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "(free,total)=cuda.mem_get_info()\n",
    "free/(1024**2),total/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
